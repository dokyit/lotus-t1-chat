{
  "name": "lotus-t1-chat",
  "displayName": "Lotus T1 Chat",
  "description": "Deepseek r1 chatbot",
  "version": "0.0.1",
  "engines": {
    "vscode": "^1.100.0"
  },
  "categories": [
    "Other"
  ],
  "activationEvents": [],
  "main": "./out/extension.js",
  "icon": "icon.png",
  "publisher": "Toby",
  "contributes": {
    "commands": [
      {
        "command": "lotus-t1-chat.helloWorld",
        "title": "Hello World"
      },
      {
        "command": "lotus-t1-chat.openChat",
        "title": "Open Lotus T1 Chat",
        "category": "Lotus T1 Chat"
      },
      {
        "command": "lotus-t1-chat.configureApiKey",
        "title": "Configure API Key",
        "category": "Lotus T1 Chat"
      }
    ],
    "configuration": {
      "title": "Lotus T1 Chat",
      "properties": {
        "lotusT1Chat.modelProvider": {
          "type": "string",
          "default": "simulation",
          "enum": ["simulation", "ollama", "openRouter", "deepseek"],
          "enumDescriptions": [
            "Simulation mode (no real API calls)",
            "Local Ollama models",
            "OpenRouter API (multiple models)",
            "Deepseek r1 model"
          ],
          "description": "Select which model provider to use",
          "scope": "application"
        },
        "lotusT1Chat.apiKey": {
          "type": "string",
          "default": "",
          "markdownDescription": "API key for Deepseek r1 model. You can get your API key from [Deepseek's website](https://deepseek.com/).",
          "scope": "application"
        },
        "lotusT1Chat.openRouterApiKey": {
          "type": "string",
          "default": "",
          "markdownDescription": "API key for OpenRouter. You can get your API key from [OpenRouter's website](https://openrouter.ai/keys).",
          "scope": "application"
        },
        "lotusT1Chat.ollamaUrl": {
          "type": "string",
          "default": "http://localhost:11434",
          "description": "URL for Ollama API (including protocol and port)",
          "scope": "application"
        },
        "lotusT1Chat.ollamaModel": {
          "type": "string",
          "default": "llama3",
          "description": "Default model to use with Ollama",
          "scope": "application"
        },
        "lotusT1Chat.openRouterModel": {
          "type": "string",
          "default": "anthropic/claude-3-haiku",
          "description": "Default model to use with OpenRouter",
          "scope": "application"
        },
        "lotusT1Chat.simulationModel": {
          "type": "string",
          "default": "gpt-4-simulation",
          "enum": ["gpt-4-simulation", "claude-simulation", "llama-simulation"],
          "description": "Model to simulate in simulation mode",
          "scope": "application"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "pretest": "npm run compile && npm run lint",
    "lint": "eslint src",
    "test": "vscode-test"
  },
  "devDependencies": {
    "@types/mocha": "^10.0.10",
    "@types/node": "20.x",
    "@types/vscode": "^1.100.0",
    "@typescript-eslint/eslint-plugin": "^8.31.1",
    "@typescript-eslint/parser": "^8.31.1",
    "@vscode/test-cli": "^0.0.10",
    "@vscode/test-electron": "^2.5.2",
    "eslint": "^9.25.1",
    "typescript": "^5.8.3"
  },
  "dependencies": {
    "axios": "^1.9.0"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/dokyit/lotus-t1-chat.git"
  }
}
